---
title: "STATS 506 HW 6"
author: "Calder Moore"
format: pdf
editor: visual
---

## Problem 1 - Rcpp

```{r}
library(Rcpp)

cppFunction("
            double C_moment(NumericVector v, int k) {
              double sum = 0;
              for (int i = 0; i < v.length(); ++i){
                sum += v[i];
              }
              
              double mu = 0.0;
              mu = (sum/v.length());
              
              double acc = 0.0;
              for (int i = 0; i < v.length(); i++) {
                acc += pow(v[i] - mu, k);
              }
          
              return acc / v.length();
            
            }")

C_moment(v = c(1,0,2,3,4.5,6.7,9,1.2), k = 3)

e1071::moment(x = c(1,0,2,3,4.5,6.7,9,1.2), order = 3, center = TRUE)
```

They match when the $\texttt{center}$ argument in $\texttt{e1071::moment}$ is set to $\texttt{TRUE}$, they won't match otherwise since the $\texttt{C_moment}$ function is calculating moments relative to the mean ($\texttt{mu}$ in the function) and so we need the other function to also be calculating centered moments.

##Problem 2 - Expanding on waldCI

### a)

Read in waldCI using $\texttt{source()}$.

```{r}
source("C:/Users/moore/Desktop/School/Master/STATS 506/STATS-506-HW-5/hw5_code.R")
```

```{r}
library(parallel)

setClass(
  "bootstrapWaldCI",
  contains = "waldCI",
  slots = c(
    data = "ANY",
    reps = "numeric",
    fun = "function",
    compute = "character",
    boot_vals = "numeric"
  )
)

#function
boot <- function(fun, data, reps, compute){

  n <- nrow(data)

  one_boot <- function(i){
    idx <- sample(seq_len(n), n, replace = TRUE)
    fun(data[idx, , drop = FALSE])
  }
  #no parallel
  if (compute == "serial") {

    replicate(reps, one_boot(1))

  } 
  #parallel
  else {

    cores <- max(1, detectCores() - 1)
    cl <- makeCluster(cores)

    clusterExport(cl,
      varlist = c("data","fun","n"),
      envir = environment()
    )

    clusterEvalQ(cl, {
      one_boot <- function(i){
        idx <- sample(seq_len(n), n, replace = TRUE)
        fun(data[idx, , drop = FALSE])
      }
    })

    out <- parSapply(cl, 1:reps, one_boot)

    stopCluster(cl)
    out
  }
}



#constructor
makeBootstrapCI <- function(fun, data, reps = 1000, level = 0.95,
                            compute = c("serial","parallel")) {

  compute <- match.arg(compute)

  boot_vals <- boot(fun, data, reps, compute)

  est <- mean(boot_vals)
  se <- sd(boot_vals)

  alpha <- 1 - level
  z <- qnorm(1 - alpha/2)

  lb <- est - z*se
  ub <- est + z*se

  new("bootstrapWaldCI",
      level = level,
      mean = est,
      sterr = se,
      lb = lb,
      ub = ub,
      data = data,
      reps = reps,
      fun = fun,
      compute = compute,
      boot_vals = boot_vals)
}


#show method
setMethod("show", "bootstrapWaldCI", function(object){
  cat(paste0("(", object@lb, ", ", object@ub, ")"), "\n")
})


#accessors
setGeneric("rebootstrap", function(object) standardGeneric("rebootstrap"))

setMethod("rebootstrap", "bootstrapWaldCI", function(object){

  boot_vals <- boot(object@fun, object@data, object@reps, object@compute)

  est <- mean(boot_vals)
  se <- sd(boot_vals)

  alpha <- 1 - object@level
  z <- qnorm(1 - alpha/2)

  object@mean <- est
  object@sterr <- se
  object@lb <- est - z*se
  object@ub <- est + z*se
  object@boot_vals <- boot_vals

  validObject(object)
  return(object)
})

```

### b)

```{r}
ci1 <- makeBootstrapCI(function(x) mean(x$y),
                       ggplot2::diamonds,
                       reps = 1000)

ci1
rebootstrap(ci1)

library(microbenchmark)

ci12 <- makeBootstrapCI(function(x) mean(x$y),
                       ggplot2::diamonds,
                       reps = 1000,
                       compute = "serial")

ci13 <- makeBootstrapCI(function(x) mean(x$y),
                       ggplot2::diamonds,
                       reps = 1000,
                       compute = "parallel")

microbenchmark(ci12)
microbenchmark(ci13)
```

$\texttt{parallel}$ method appears to be faster.

### c)

```{r}
dispCoef <- function(dat) {
  mod <- lm(mpg ~ cyl + disp + wt, data = dat)
  return(coef(mod)[["disp"]])
}

ci2 <- makeBootstrapCI(dispCoef,
                       mtcars,
                       reps = 1000)
ci2
rebootstrap(ci2)

ci22 <- makeBootstrapCI(dispCoef,
                       mtcars,
                       reps = 1000,
                       compute = "serial")

ci23 <- makeBootstrapCI(dispCoef,
                       mtcars,
                       reps = 1000,
                       compute = "parallel")

microbenchmark(ci22)
microbenchmark(ci23)
```

$\texttt{series}$ is the faster method here.

## Problem 3 - Large Data

### a)

```{r}
#source("https://dept.stat.lsa.umich.edu/~jerrick/courses/stat506_f25/ps06q3.R")

#rescale
for (i in unique(df$country)) {
  
  id <- (df$country == i)
  n <- sum(id)
  
  if(n > 1) {
    df$gpa_std[id] <- as.vector(scale(df$prior_gpa[id]))
    df$forum_posts_std[id] <- as.vector(scale(df$forum_posts[id]))
    df$quiz_attempts_std[id] <- as.vector(scale(df$quiz_attempts[id]))
  }
  else {
    df$GPA_std[id] <- 0
    df$forum_posts_std[id] <- 0
    df$quiz_attempts_std[id] <- 0
  }
}

#make models
library(lme4)

countries <- unique(df$country)
models <- list()
runtimes <- numeric(length(countries))

for (i in seq_along(countries)) {
  data_i <- df[df$country == countries[i], ]
  
  #run time
  runtimes[i] <- system.time({
    models[[i]] <- glmer(completed_course ~ gpa_std + forum_posts_std + quiz_attempts_std + (1 | device_type),
      data = data_i,
      family = binomial
    )
  })["elapsed"]
}

# Display running times
runtimes

```

Visualization:

```{r}
library(ggplot2)

coef_forum <- sapply(models, function(mod) {
  fixef(mod)["forum_posts_std"]
})
names(coef_forum) <- countries


coef_df <- data.frame(
  country = names(coef_forum),
  forum_coef = coef_forum
)

ggplot(coef_df, aes(x = country, y = forum_coef)) +
  geom_col() +
  labs(
    title = "Estimated Effect of Forum Posts on Course Completion",
    y = "Coefficient (standardized forum posts)",
    x = "Country"
  )

```

### b)

Use parallel processing to try and improve the run time. Part a) took forever.

```{r}
library(parallel)

countries <- unique(df$country)

#model per country
fit_model <- function(c) {
  data_i <- df[df$country == c, ]
  glmer(completed_course ~ gpa_std + forum_posts_std + quiz_attempts_std + (1 | device_type),
        data = data_i, family = binomial)
}

#run time
time_total <- system.time({


  cl <- makeCluster(detectCores() - 1)
  clusterExport(cl, c("df", "fit_model"))
  clusterEvalQ(cl, library(lme4))
  
  models <- parLapply(cl, countries, fit_model)
  stopCluster(cl)
  
  names(models) <- countries

  coef_forum <- sapply(models, function(mod) fixef(mod)["forum_posts_std"])
  names(coef_forum) <- countries
})

coef_df_par <- data.frame(
  country = names(coef_forum),
  forum_coef = as.numeric(coef_forum)
)

# Show results
time_total
coef_df
coef_df_par

```

The results match. The total run time for this script was 518.76 seconds.

## Problem 4 - data.table

```{r}

```


